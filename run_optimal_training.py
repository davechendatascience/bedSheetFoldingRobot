#!/usr/bin/env python3
"""
Optimal Training Script with All Improvements Integrated
This script runs the complete training pipeline with all optimizations we've developed.
"""

import os
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), "src"))
import json
from datetime import datetime

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from post_keypoint_detection_model_training import main_training_pipeline, DEFAULT_CONFIG

def run_optimal_training():
    """Run the optimal training configuration with all improvements."""
    
    print("ðŸš€ Starting Optimal Training with All Improvements")
    print("=" * 60)
    
    # Create optimal configuration
    config = DEFAULT_CONFIG.copy()
    
    # Optimal settings based on our testing
    config.update({
        "num_epochs": 300,  # Full training
        "batch_size": 32,   # Optimal batch size
        "learning_rate": 3e-5,  # Optimal learning rate
        "use_stronger_augmentation": True,  # Include Cutout + stronger transforms
        "use_mixup": True,  # Mixup for regularization
        "use_fp16": True,  # FP16 for speed
        "gradient_accumulation_steps": 2,  # Gradient accumulation
        "early_stopping_patience": 20,  # Early stopping
        "save_interval": 10,  # Save every 10 epochs
        "use_quantization": False,  # Skip QAT for now
        "export_model": True,  # Export final model
    })
    
    print("ðŸ“‹ Configuration Summary:")
    print(f"  â€¢ Epochs: {config['num_epochs']}")
    print(f"  â€¢ Batch Size: {config['batch_size']}")
    print(f"  â€¢ Learning Rate: {config['learning_rate']}")
    print(f"  â€¢ Stronger Augmentation: {config['use_stronger_augmentation']} âœ…")
    print(f"  â€¢ Mixup: {config['use_mixup']} âœ…")
    print(f"  â€¢ FP16 Training: {config['use_fp16']} âœ…")
    print(f"  â€¢ Gradient Accumulation: {config['gradient_accumulation_steps']} âœ…")
    print(f"  â€¢ Early Stopping: {config['early_stopping_patience']} epochs âœ…")
    print(f"  â€¢ Save Interval: Every {config['save_interval']} epochs âœ…")
    
    print("\nðŸ”§ Integrated Improvements:")
    print("  âœ… Fixed coordinate system mapping")
    print("  âœ… Confidence-based masking refinement")
    print("  âœ… Single peak detection per keypoint")
    print("  âœ… Proper train/eval data separation")
    print("  âœ… Cutout augmentation (in StrongerAugmentation)")
    print("  âœ… Multi-stage learning rate scheduling")
    print("  âœ… Gradient clipping and accumulation")
    print("  âœ… Early stopping with best model saving")
    print("  âœ… FP16 mixed precision training")
    print("  âœ… Label smoothing and dropout")
    
    print("\nðŸ“Š Expected Performance:")
    print("  â€¢ Training Loss Target: < 2.0")
    print("  â€¢ Validation Loss Target: < 3.0")
    print("  â€¢ Overfitting Ratio Target: < 1.5x")
    print("  â€¢ Convergence: Stable within 50-100 epochs")
    
    print("\n" + "=" * 60)
    print("ðŸŽ¯ Starting Training Pipeline...")
    print("=" * 60)
    
    # Create timestamp for this run
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    config['model_save_path'] = f"models/keypoint_model_optimal_{timestamp}"
    config['results_dir'] = f"results/optimal_{timestamp}"
    
    # Create results directory
    os.makedirs(config['results_dir'], exist_ok=True)
    
    try:
        # Run training pipeline
        model, history = main_training_pipeline(config)
        
        print("\n" + "=" * 60)
        print("ðŸŽ‰ OPTIMAL TRAINING COMPLETED SUCCESSFULLY!")
        print("=" * 60)
        
        # Print final results
        if history and 'train_loss' in history and len(history['train_loss']) > 0:
            final_train_loss = history['train_loss'][-1]
            best_train_loss = min(history['train_loss'])
            
            print(f"ðŸ“ˆ Training Results:")
            print(f"  â€¢ Final Training Loss: {final_train_loss:.4f}")
            print(f"  â€¢ Best Training Loss: {best_train_loss:.4f}")
            
            if 'val_loss' in history and len(history['val_loss']) > 0:
                final_val_loss = history['val_loss'][-1]
                best_val_loss = min(history['val_loss'])
                
                print(f"  â€¢ Final Validation Loss: {final_val_loss:.4f}")
                print(f"  â€¢ Best Validation Loss: {best_val_loss:.4f}")
                
                # Calculate overfitting ratio
                overfitting_ratio = final_val_loss / final_train_loss if final_train_loss > 0 else float('inf')
                print(f"  â€¢ Overfitting Ratio: {overfitting_ratio:.2f}x")
                
                # Performance assessment
                if overfitting_ratio < 1.5:
                    print("  âœ… Excellent: Low overfitting")
                elif overfitting_ratio < 2.0:
                    print("  âš ï¸ Good: Moderate overfitting")
                else:
                    print("  âŒ High: Significant overfitting")
                
                # Loss targets assessment
                if final_train_loss < 2.0:
                    print("  âœ… Training Loss Target Achieved!")
                else:
                    print("  âš ï¸ Training Loss Target Not Met")
                
                if final_val_loss < 3.0:
                    print("  âœ… Validation Loss Target Achieved!")
                else:
                    print("  âš ï¸ Validation Loss Target Not Met")
        
        # Check model files
        model_path = f"{config['model_save_path']}.pth"
        if os.path.exists(model_path):
            print(f"âœ… Model saved: {model_path}")
        else:
            print(f"âš ï¸ Model file not found: {model_path}")
        
        # Check results
        if os.path.exists(config['results_dir']):
            result_files = [f for f in os.listdir(config['results_dir']) if f.endswith('.png')]
            print(f"âœ… Results generated: {len(result_files)} visualization files")
        else:
            print(f"âš ï¸ Results directory not found: {config['results_dir']}")
        
        # Save training history
        history_path = f"{config['results_dir']}/training_history.json"
        with open(history_path, 'w') as f:
            json.dump(history, f, indent=2)
        print(f"âœ… Training history saved: {history_path}")
        
        print("\n" + "=" * 60)
        print("ðŸŽ¯ ALL SYSTEMS WORKING OPTIMALLY!")
        print("=" * 60)
        
        return True, history
        
    except Exception as e:
        print(f"\nâŒ TRAINING FAILED!")
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def print_augmentation_details():
    """Print details about the augmentation pipeline."""
    print("\nðŸ” Augmentation Pipeline Details:")
    print("=" * 40)
    
    print("ðŸ“¦ StrongerAugmentation includes:")
    print("  â€¢ RandomRotateFlip (p=0.5)")
    print("  â€¢ ColorJitter (brightness=0.1, contrast=0.1, p=0.5)")
    print("  â€¢ GaussianNoise (std=3.0, p=0.4)")
    print("  â€¢ Cutout (p=0.3, size=16) âœ…")
    
    print("\nðŸ“¦ MinimalAugmentation includes:")
    print("  â€¢ RandomRotateFlip (p=0.3)")
    print("  â€¢ ColorJitter (brightness=0.05, contrast=0.05, p=0.3)")
    print("  â€¢ GaussianNoise (std=2.0, p=0.2)")
    
    print("\nðŸ“¦ Additional Features:")
    print("  â€¢ Mixup (alpha=0.2)")
    print("  â€¢ Proper train/eval separation")
    print("  â€¢ Confidence-based masking")
    print("  â€¢ Single peak detection")

if __name__ == "__main__":
    print_augmentation_details()
    
    # Ask for confirmation
    response = input("\nðŸ¤” Proceed with optimal training? (y/n): ").lower().strip()
    
    if response in ['y', 'yes', '']:
        success, history = run_optimal_training()
        
        if success:
            print("\nâœ… Optimal training completed successfully!")
            print("ðŸŽ¯ Your model is now ready for deployment!")
        else:
            print("\nâŒ Training failed. Please check the error messages above.")
    else:
        print("\nâ¹ï¸ Training cancelled by user.")
